[{"content":"Environment Unity 2021.3.16f1\nUniversal Render Pipeline 12.0.0\nIntroduction I recently finished The Legend of Zelda: Tears of the Kingdom. To me as an indie game developer, it felt like a text book of open world game design. I had a lot of fun playing it and I learned a lot from it.\nOne of the things I noticed is the rain drop effect that react to the uppper edges of the scene. It\u0026rsquo;s a very subtle effect but it actually guided me through the thunder island where the player\u0026rsquo;s visibility range was less than 1 meter. In the image below, you can see that the rain drops react to the edge of the mining cart rails, which tells the player that there is a path to continue the journey. I guess probably the game designer didn\u0026rsquo;t intend to do this, but it\u0026rsquo;s Nintendo, you never know.\nThis effect was one of the a few things I could rely on while exploring the island, so I decided to implement it in Unity as a render feature, just to show my appreciation to those little rain drops.\nDemo How It Works The effect basically composes of two parts: Edge detection with angle limitation and a fast scrolling noise map.\nEdge Detection From the image above, we can see that the effect is applied even in places that have no gradient such as the rails. Therefore, it has to be using the depth buffer. With that being clear, We just need to apply a sobel edge deteciton on the depth buffer and get a edge mask.\nIf you are not familar with Sobel Edge Detection. Here is a quick explanation. Sobel Edge Detection is a simple edge detection algorithm that uses two 3x3 kernels to calculate the gradient of the image.\nHorizontal:\n-1 0 1\r-2 0 2\r-1 0 1 Vertical:\n1 2 1\r0 0 0\r-1 -2 -1 Apply the two kernels respectively on each pixel(x,y) in the depth texture(depth):\nhorizontal = depth[x-1,y-1] * -1 + depth[x,y-1] * 0 + depth[x+1,y-1] * 1\r+ depth[x-1,y] * -2 + depth[x,y] * 0 + depth[x+1,y] * 2\r+ depth[x-1,y+1] * -1 + depth[x,y+1] * 0 + depth[x+1,y+1] * 1\rvertical = depth[x-1,y-1] * -1 + depth[x,y-1] * -2 + depth[x+1,y-1] * -1\r+ depth[x-1,y] * 0 + depth[x,y] * 0 + depth[x+1,y] * 0\r+ depth[x-1,y+1] * 1 + depth[x,y+1] * 2 + depth[x+1,y+1] * 1 Then we can calculate the magnitude of the gradient by taking the square root of the sum of the squares of the two gradients:\nmagnitude = sqrt(horizontal * horizontal + vertical * vertical) The magnitude is the value we are looking for. It describes the color gradient between the pixel and its neighbors. The higher the value, the more likely it is an edge.\nFrom here, we do need one more value to describe the \u0026ldquo;direction\u0026rdquo; of the gradient. If it doesn\u0026rsquo;t make sense to you. Just think about the gradient as a vector, composed of the horizontal gradient value we calculated before and the vertical gradient value. We can calculate the angle between the gradient vector and the horizontal axis by taking the arctangent of the vertical gradient over the horizontal gradient.\nangle = atan2(vertical, horizontal) It gives us a value between -pi and pi, representing the angle of the vector in radian.\nNow we have the magnitude and the angle of the gradient. We can use them to create a mask that only shows the edges we want, which are the edges that are facing up.\nNoise Map Congradulations to you and future me that forgot how I did this! for making it this far. Now we have the edge mask, we can just multiply a scrolling noise map on it to get the final mask.\nAfter that, configure the settings as you like: thickness, sobel threshold, rain drop scale, drop speed, drop color, etc.\nFor noise map, I used a simple 2D perlin noise map that I generated from this website: http://kitfox.com/projects/perlinNoiseMaker/\nImplementation Final Code ZeldaRainDropFeature.cs\nusing UnityEngine; using UnityEngine.Rendering; using UnityEngine.Rendering.Universal; using UnityEngine.Serialization; public class ZeldaRainDropFeature : ScriptableRendererFeature { [SerializeField] public Settings settings = new Settings(); private RainDropRenderPass m_RenderPass; public override void Create() { m_RenderPass = new RainDropRenderPass(settings) { renderPassEvent = settings.renderPassEvent }; } public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) { if (settings.rainDropShader != null \u0026amp;\u0026amp; settings.rainDropShader != null) { renderer.EnqueuePass(m_RenderPass); } } private class RainDropRenderPass : ScriptableRenderPass { private Settings m_Settings; private RenderTargetHandle m_ResultTex; //camera color public RainDropRenderPass(Settings settings) { m_Settings = settings; } public override void Configure(CommandBuffer cmd, RenderTextureDescriptor cameraTextureDescriptor) { var descriptor = cameraTextureDescriptor; descriptor.colorFormat = RenderTextureFormat.ARGB32; descriptor.enableRandomWrite = true; cmd.GetTemporaryRT(m_ResultTex.id, descriptor); } public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) { if (!m_Settings.previewInSceneView \u0026amp;\u0026amp; (renderingData.cameraData.isSceneViewCamera || renderingData.cameraData.isPreviewCamera)) { return; } CommandBuffer cmd = CommandBufferPool.Get(name: \u0026#34;Screen Door Transparency\u0026#34;); cmd.Clear(); //cache color target var cam = renderingData.cameraData.renderer; var shader = m_Settings.rainDropShader; var mainKernel = shader.FindKernel(\u0026#34;ScreenSpaceRainDrop\u0026#34;); //sobel cmd.SetComputeTextureParam(shader, mainKernel, \u0026#34;_InputColorTex\u0026#34;, cam.cameraColorTarget); cmd.SetComputeTextureParam(shader, mainKernel, \u0026#34;_InputDepthTex\u0026#34;, cam.cameraDepthTarget); cmd.SetComputeTextureParam(shader, mainKernel, \u0026#34;_NoiseTex\u0026#34;, m_Settings.noiseTex); cmd.SetComputeIntParam(shader, \u0026#34;_Thickness\u0026#34;, m_Settings.thickness); cmd.SetComputeFloatParam(shader, \u0026#34;_EdgeThreshold\u0026#34;, m_Settings.sobelThreshold); //noise cmd.SetComputeFloatParam(shader, \u0026#34;_RainDropScale\u0026#34;, m_Settings.rainDropScale); cmd.SetComputeIntParam(shader, \u0026#34;_NoiseWidth\u0026#34;, m_Settings.noiseTex.width); cmd.SetComputeIntParam(shader, \u0026#34;_NoiseHeight\u0026#34;, m_Settings.noiseTex.height); cmd.SetComputeVectorParam(shader, \u0026#34;_Time\u0026#34;, Shader.GetGlobalVector(\u0026#34;_Time\u0026#34;)); cmd.SetComputeFloatParam(shader, \u0026#34;_DropSpeed\u0026#34;, m_Settings.dropSpeed); cmd.SetComputeVectorParam(shader, \u0026#34;_DropColor\u0026#34;, m_Settings.dropColor); //output cmd.SetComputeTextureParam(shader, mainKernel, \u0026#34;_OutputTex\u0026#34;, m_ResultTex.Identifier()); cmd.SetComputeIntParam(shader, \u0026#34;_Width\u0026#34;, renderingData.cameraData.camera.scaledPixelWidth); cmd.SetComputeIntParam(shader, \u0026#34;_Height\u0026#34;, renderingData.cameraData.camera.scaledPixelHeight); int threadGroupX = Mathf.CeilToInt(renderingData.cameraData.camera.scaledPixelWidth / 8.0f); int threadGroupY = Mathf.CeilToInt(renderingData.cameraData.camera.scaledPixelHeight / 8.0f); cmd.DispatchCompute(shader, mainKernel, threadGroupX, threadGroupY, 1); cmd.Blit(m_ResultTex.id, cam.cameraColorTarget); context.ExecuteCommandBuffer(cmd); CommandBufferPool.Release(cmd); context.Submit(); } public override void FrameCleanup(CommandBuffer cmd) { cmd.ReleaseTemporaryRT(m_ResultTex.id); } } [System.Serializable] public class Settings { public ComputeShader rainDropShader; public Texture2D noiseTex; public Color dropColor = Color.white; [Range(0, 20)] public int thickness = 3; [Range(0f, 1f)] public float sobelThreshold = 0.166f; [Range(0f, 1f)] public float rainDropScale = 0.5f; public float dropSpeed = 100f; public RenderPassEvent renderPassEvent = RenderPassEvent.AfterRenderingTransparents; public bool previewInSceneView = true; } } ScreenSpaceRainDrop.compute\n#pragma kernel ScreenSpaceRainDrop RWTexture2D\u0026lt;float4\u0026gt; _OutputTex; Texture2D _InputColorTex; Texture2D _InputDepthTex; Texture2D _NoiseTex; int _Thickness; float _RainDropScale; float _EdgeThreshold; int _Width; int _Height; int _NoiseWidth; int _NoiseHeight; float4 _Time; float _DropSpeed; float4 _DropColor; static const float PI = 3.14159265f; [numthreads(8,8,1)] void ScreenSpaceRainDrop(uint3 id : SV_DispatchThreadID) { if (int(id.x) + _Thickness \u0026gt;= _Width || int(id.y) + _Thickness \u0026gt;= _Height || int(id.x) - _Thickness \u0026lt; 0 || int(id.y) - _Thickness \u0026lt; 0) { _OutputTex[id.xy] = _InputColorTex[id.xy]; return; } //p6 p7 p8 //p3 p4 p5 //p0 p1 p2 float depthSqr = _InputDepthTex[id.xy].r * _InputDepthTex[id.xy].r; int sobelX = int(id.x); int sobelY = int(id.y) - _Thickness * depthSqr; int2 p0 = int2(sobelX - _Thickness * depthSqr, sobelY + _Thickness * depthSqr); int2 p1 = int2(sobelX, sobelY - _Thickness); int2 p2 = int2(sobelX + _Thickness * depthSqr, sobelY - _Thickness * depthSqr); int2 p3 = int2(sobelX - _Thickness * depthSqr, sobelY); int2 p5 = int2(sobelX + _Thickness * depthSqr, sobelY); int2 p6 = int2(sobelX - _Thickness * depthSqr, sobelY + _Thickness * depthSqr); int2 p7 = int2(sobelX, sobelY + _Thickness * depthSqr); int2 p8 = int2(sobelX + _Thickness * depthSqr, sobelY + _Thickness * depthSqr); // derivative in two directions float dxPosX = _InputDepthTex[p0].r * -1 + _InputDepthTex[p3].r * -2 + _InputDepthTex[p6].r * -1 + _InputDepthTex[p2].r + _InputDepthTex[p5].r * 2 + _InputDepthTex[p8].r; float dxPosY = _InputDepthTex[p0].r * -1 + _InputDepthTex[p1].r * -2 + _InputDepthTex[p2].r * -1 + _InputDepthTex[p6].r + _InputDepthTex[p7].r * 2 + _InputDepthTex[p8].r; //edge mask float dx = sqrt(dxPosX * dxPosX + dxPosY * dxPosY); float edgeMask = step(_EdgeThreshold, dx); //angle mask float dir = atan2(dxPosY, dxPosX); dir = (dir + PI) / (2 * PI); float angleMask = step(dir, 0.5f); edgeMask *= angleMask; //noise mask int noiseX = int((id.x + _Time.g * _DropSpeed) % _NoiseWidth); int noiseY = int((id.y + _Time.g * _DropSpeed) % _NoiseHeight); float noiseMask = step(_RainDropScale, _NoiseTex[int2(noiseX, noiseY)].r); float finalMask = edgeMask * angleMask * noiseMask; float4 result = lerp(_InputColorTex[id.xy], _DropColor, finalMask * _DropColor.a); _OutputTex[id.xy] = dx; } Improvement There are a few things I can improve in the future:\nChange the effect to Layer-based or Object-based for some very specific effects. But it will cost more performance and Tears of the kindom didn\u0026rsquo;t do that, so I guess it\u0026rsquo;s not necessary. Play with the noise map to get a better looking rain drop. For example, downscale the noise map to get more blurred rain drops and save performance. ","permalink":"https://sky-haihai.github.io/Yaotian-Huang/posts/gamedev/recreating-the-rain-drop-effect-in-the-legend-of-zelda-totk/","summary":"Environment Unity 2021.3.16f1\nUniversal Render Pipeline 12.0.0\nIntroduction I recently finished The Legend of Zelda: Tears of the Kingdom. To me as an indie game developer, it felt like a text book of open world game design. I had a lot of fun playing it and I learned a lot from it.\nOne of the things I noticed is the rain drop effect that react to the uppper edges of the scene.","title":"Recreating the Rain Drop Effect in The Legend of Zelda: TOTK"},{"content":"Introduction In this post, I will be discussing how I implemented a Screen-door transparency effect in Unity using URP 12. This effect is used to simulate the look of a transparent object by applying Bayer Ordered Dithering to the semi-transparent object. This effect can be used in games to give the player a better view of the character even when the character is coverd by obstacles.\nHow it works You can think of this effect as using a sharp pencil to poke a dense grid of holes onto a paper to reveal the objects behind the paper. Also you can use a Threshold value to control how transparent the object is, a.k.a, how density of the grid of holes.\nShader-wise speaking, the effect can be divided into following steps:\nPrepare a temporary texture to store the result of the effect. Render a character-layer-only color texture using a character layer filter. Render a character layer depth texture. Render a obstacle layer depth texture to be compared with the character depth to determine whether the character is covered by obstacles. Send these textures with the camera RenderTarget as an texture to the compute shader to let it draw the final result onto the temporary texture we created in step#1. (Optional) Resize the temporary texture to the size of the camera RenderTarget. Blit the temporary texture onto the camera RenderTarget. Demo Here\u0026rsquo;s a quick demo of the effect.\nAnother detailed explanation of the effect, showcasing how this effect reacts to different threshold values. From here, if you are fimiliar with the concept of render feature and render pass, and just want to see the ordered dithering part, you can skip to the #execute-method section. To see the final code, skip to here: #source-code\nEnvironment Unity 2021.3.16f1 URP 12.0.0 Implementation From Requirements The first thing to do before implementing anything for me in most development cases is to abstract requirements into a function and determine the inputs and outputs.\nIn this project, the requirements are:\nLayer-based. The user should be able to specify both the Character Layers to apply the Screen-door transparency effect on, and the layers to be used as the Obstacle Layers. Ordered Dithering algorithm. The user should be able to specify the Threshold of the dithering. Screen Space. Since the effect is layer-based, this effect should be applied in the Post-Processing Stage. Threshold. The user should be able to specify the threshold value for the Screen-door transparency effect to get the desired transparency effect. To Inputs From these requirements, we can determine that the inputs are:\nInput Type Character LayerMask LayerMask Obstacle LayerMask LayerMask Ordered Dithering Shader Compute Shader Threshold Value float Render Pass Event RenderPassEvent Put into a Setting class, we have:\n[System.Serializable] public class Settings { public ComputeShader computeShader; public LayerMask targetLayer; public LayerMask obstacleLayer; public RenderPassEvent renderPassEvent = RenderPassEvent.AfterRenderingTransparents; [Range(0, 1f)] public float ditheringThreshold = 0.5f; //For Debugging(Optional) public bool previewInSceneView = true; } Render Pass Structure Now to create a new C# class that inherits ScriptableRenderPass, including settings we just created.\nprivate class ScreenDoorRenderPass : ScriptableRenderPass { private Settings m_Settings; public ScreenDoorRenderPass(Settings settings) { m_Settings = settings; } public override void Configure(CommandBuffer cmd, RenderTextureDescriptor cameraTextureDescriptor) { //Configure render target and render texture } public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) { //Construct and execute command buffer } public override void FrameCleanup(CommandBuffer cmd) { //Release temporary textures } } Variables Inside of the render pass, we need to create a few variables to store the temporary render textures and render target handles.\nprivate RenderTargetHandle m_TempCameraOpaque; //camera color private RenderTexture m_TargetOpaqueTexture; //target layer color private RenderTexture m_TargetDepthTexture; //target layer depth private RenderTexture m_ObstacleDepthTexture; //obstacle layer depth Note: Don\u0026rsquo;t be scared by the type names. RenderTargetHandle, RenderTargetIdentifier, RenderTexture, etc. They all does the same thing: storing a texture.\nIn GPU, each texture is associated with a unique ID. RenderTargetHandle, RenderTargetIdentifier are just wrappers around the texture ID while RenderTexture is a wrapper around the texture itself.\nConfigure Method Now we can configure the render target and render texture in the Configure function.\npublic override void Configure(CommandBuffer cmd,RenderTextureDescriptor cameraTextureDescriptor) { var descriptor = cameraTextureDescriptor; descriptor.enableRandomWrite = true; cmd.GetTemporaryRT(m_TempCameraOpaque.id, descriptor); m_TargetOpaqueTexture = RenderTexture.GetTemporary(cameraTextureDescriptor.width, cameraTextureDescriptor.height, 0, RenderTextureFormat.ARGB32); m_TargetDepthTexture = RenderTexture.GetTemporary(cameraTextureDescriptor.width, cameraTextureDescriptor.height, 16, RenderTextureFormat.Depth); m_ObstacleDepthTexture = RenderTexture.GetTemporary(cameraTextureDescriptor.width, cameraTextureDescriptor.height, 16, RenderTextureFormat.Depth); } Frame Cleanup Method Finish the FrameCleanup function while we still remember.\npublic override void FrameCleanup(CommandBuffer cmd) { cmd.ReleaseTemporaryRT(m_TempCameraOpaque.id); RenderTexture.ReleaseTemporary(m_TargetOpaqueTexture); RenderTexture.ReleaseTemporary(m_TargetDepthTexture); RenderTexture.ReleaseTemporary(m_ObstacleDepthTexture); } Execute Method Finally, we can start to write the Execute function where the actual rendering logic locates. Since the code is relatively long, I will explain it in chunks.\n// Fetch a command buffer from the command pool, remember to release it at the end of the function CommandBuffer cmd = CommandBufferPool.Get(name: \u0026#34;Screen Door Transparency\u0026#34;); // Clear the command buffer in case there are some commands left cmd.Clear(); Command buffers are used to store GPU commands. We can think of it as a list of GPU commands.\nAfter fetching the command buffer, prepare the drawing settings for drawing opaque(colored) texture for Character layer(the layer that\u0026rsquo;s needed to be revealed from obstacles).\n// Prepare the drawwing setting for opaque texture (for character layer) var drawOpaqueSettings = CreateDrawingSettings(new ShaderTagId(\u0026#34;UniversalForward\u0026#34;), ref renderingData, SortingCriteria.BackToFront); // Prepare the drawing setting for depth-only mode var drawDepthSettings = CreateDrawingSettings(new ShaderTagId(\u0026#34;DepthOnly\u0026#34;), ref renderingData, renderingData.cameraData.defaultOpaqueSortFlags); // Prepare the filtering setting for character layer var targetFilter = new FilteringSettings(RenderQueueRange.all, m_Settings.targetLayer.value); // Prepare the filtering setting for obstacle layer var obstacleFilter = new FilteringSettings(RenderQueueRange.all, m_Settings.obstacleLayer.value); Now render all the textures using the settings we just created.\n//draw target opaque cmd.SetRenderTarget(m_TargetOpaqueTexture); cmd.ClearRenderTarget(true, true, Color.clear); context.ExecuteCommandBuffer(cmd); cmd.Clear(); context.DrawRenderers(renderingData.cullResults, ref drawOpaqueSettings, ref targetFilter); //draw target depth cmd.SetRenderTarget(m_TargetDepthTexture); cmd.ClearRenderTarget(true, false, Color.clear); context.ExecuteCommandBuffer(cmd); cmd.Clear(); context.DrawRenderers(renderingData.cullResults, ref drawDepthSettings, ref targetFilter); //draw obstacle depth cmd.SetRenderTarget(m_ObstacleDepthTexture); cmd.ClearRenderTarget(true, false, Color.clear); context.ExecuteCommandBuffer(cmd); cmd.Clear(); context.DrawRenderers(renderingData.cullResults, ref drawDepthSettings, ref obstacleFilter); //reset render target var cam = renderingData.cameraData.renderer; cmd.SetRenderTarget(cam.cameraColorTarget, cam.cameraDepthTarget); //cache camera color which will be used later in the compute shader as a source texture cmd.Blit(cam.cameraColorTarget, m_TempCameraOpaque.Identifier()); Note\nThe commands inside CommandBuffer won\u0026rsquo;t be executed before context.ExecuteCommandBuffer(cmd). Therefore context.ExecuteCommandBuffer(cmd) is needed before every context.DrawRenderers(...) to make sure the commands are executed before we draw any textures.\nAt this point, we have rendered all the textures we need. Now we can pass them to the compute shader:\n//get kernel var shader = m_Settings.computeShader; var mainKernel = shader.FindKernel(\u0026#34;BayerOrderedDithering\u0026#34;); //set textures and parameters cmd.SetComputeTextureParam(shader, mainKernel, \u0026#34;_InputTexture\u0026#34;, cam.cameraColorTarget); cmd.SetComputeTextureParam(shader, mainKernel, \u0026#34;_TargetOpaqueTexture\u0026#34;, m_TargetOpaqueTexture); cmd.SetComputeTextureParam(shader, mainKernel, \u0026#34;_TargetDepthTexture\u0026#34;, m_TargetDepthTexture); cmd.SetComputeTextureParam(shader, mainKernel, \u0026#34;_ObstacleDepthTexture\u0026#34;, m_ObstacleDepthTexture); cmd.SetComputeTextureParam(shader, mainKernel, \u0026#34;_OutputTexture\u0026#34;, m_TempCameraOpaque.Identifier()); cmd.SetComputeFloatParam(shader, \u0026#34;_DitherThreshold\u0026#34;, m_Settings.ditheringThreshold); //define thread group size int threadGroupX = Mathf.CeilToInt(renderingData.cameraData.camera.scaledPixelWidth / 8.0f); int threadGroupY = Mathf.CeilToInt(renderingData.cameraData.camera.scaledPixelHeight / 8.0f); //dispatch compute shader cmd.DispatchCompute(shader, mainKernel, threadGroupX, threadGroupY, 1); //draw the result back to screen cmd.Blit(m_TempCameraOpaque.id, cam.cameraColorTarget); The denominator when calculating the threadGroup sizes must match the numthreads attribute in the compute shader to get a full screen processing, in my compute shader it is set to [numthreads(8,8, 1)], there fore we divide the screen width and height by 8.\nAt this point, we have defined all the commands for the ComputeBuffer. Now we just need to execute it.\n//submit commands to the GPU context.ExecuteCommandBuffer(cmd); //release command buffer from RAM CommandBufferPool.Release(cmd); //might be unnecessary, unity will do this for us in the end of execute method, but just in case context.Submit(); Now we have finished our ScreenDoorRenderPass.\nRender Feature To use the render pass we just created, create a new C# class that inherits ScriptableRendererFeature.\nusing UnityEngine; using UnityEngine.Rendering; using UnityEngine.Rendering.Universal; public class ScreenDoorRenderFeature : ScriptableRendererFeature { [SerializeField] public Settings settings = new Settings(); ScreenDoorRenderPass m_RenderPass; public override void Create() { m_RenderPass = new ScreenDoorRenderPass(settings) { renderPassEvent = settings.renderPassEvent }; } public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) { if (settings.computeShader != null \u0026amp;\u0026amp; settings.targetLayer != 0 \u0026amp;\u0026amp; settings.obstacleLayer != 0) { renderer.EnqueuePass(m_RenderPass); } } } What\u0026rsquo;s going on here is relatively simple. We create a new ScreenDoorRenderPass and set its renderPassEvent to the one we defined in the inspector. Then we add the render pass to the renderer\u0026rsquo;s queue.\nAnd that\u0026rsquo;s it! Now we can use the render feature in our renderer settings.\nSource Code Source Code: Screen Door Transparency\nRenderer Asset Note The basic setup for an URP project is not part of the scope for this article. If you don\u0026rsquo;t know how to do that, please refer to this manual page: InstallURPIntoAProject.\nMake sure to enable opaque texture and depth texture in the URP asset.\nFind your URP renderer asset and add the render feature we just created.\nDrag the compute shader we create eariler in, and set the target layer to the ones you want to reveal from obstacles and as the name suggested , set all the environment layers as obstacle layer.\nFor example, in the video demo, the layer for the green boxes are set to be osbatcle layer, and the layer for the orange balls are set to be target layer.\nFuture Improvements Add a dropdown menu to the render feature to allow the user to select different sizes of Bayer Matrixes. Support Transparent objects. Optimize the performance of the render feature by reducing the size of the temporary textures. The current project I\u0026rsquo;m working on doesn\u0026rsquo;t require a object-based Screen Door Effect. But if you need it, you can just add a oredered dithering pass to the shader. References Ordered Dithering - Computerphile\nhttps://youtu.be/IviNO7iICTM\nOrdered dithering - Wikipedia\nhttps://en.wikipedia.org/wiki/Ordered_dithering\n","permalink":"https://sky-haihai.github.io/Yaotian-Huang/posts/gamedev/layer-based-screen-door-transparency-effect-using-unity-urp-12/","summary":"Introduction In this post, I will be discussing how I implemented a Screen-door transparency effect in Unity using URP 12. This effect is used to simulate the look of a transparent object by applying Bayer Ordered Dithering to the semi-transparent object. This effect can be used in games to give the player a better view of the character even when the character is coverd by obstacles.\nHow it works You can think of this effect as using a sharp pencil to poke a dense grid of holes onto a paper to reveal the objects behind the paper.","title":"Layer-based Screen-Door Transparency Effect using Unity URP 12"},{"content":"Source code: Github Repo\nView Live Demo: Diet Dashboard\n","permalink":"https://sky-haihai.github.io/Yaotian-Huang/posts/uni/creating-a-diet-dashboard-based-on-angular/","summary":"Source code: Github Repo\nView Live Demo: Diet Dashboard","title":"Creating a Diet Dashboard Based on Angular"},{"content":"View the full project here: Github Repo\nIntroduction In a recent academic project, I implemented a secured web information system using Java Servlet and created several content pages including AboutMe, Skills, and Contact pages for testing my system.\nThe goal was to implement a web application that could allow users to login, logout and view their profile. The application also had to be secured against unauthorized access such as directly typing the content page URL.\nThe URL of the deployed website on the school SIT server is: http://sit.itec.yorku.ca:8080/itec4020grp9/\n⚠️ Note\nThe website is deployed on the school System Integration Testing(SIT) server. Access it requires a York University VPN. Please contact me if you are interested and I will send you a video demo of the website.\nEnvironment Server Tomcat 7.0.76 JavaSE 8 Local JavaSE 8 ⚠️ Must match the version of the server side VS Code (with the following extensions) Language Support for Java(TM) by Red Hat v1.18.0 Project Manager for Java v0.22.0 Structure Overview website\r├── css\r│ ├── preventPrint.css\r│ ├── useDefaultCursor.css\r│ └── ...\r├── images // images that do not need to be protected\r├── js\r│ ├── disableDragging.js\r│ ├── disableSavingImg.js\r│ └── disableSelection.js\r├── src\r│ ├── util\r│ │ └── ImageHelper.java\r│ ├── LoginServlet.java\r│ ├── LogoutServlet.java\r│ ├── AboutMeServlet.java\r│ └── ...\r├── WEB-INF\r│ ├── classes\r│ │ ├── util\r│ │ │ ├── ImageHelper.class\r│ │ ├── LoginServlet.class\r│ │ ├── LogoutServlet.class\r│ │ ├── AboutMeServlet.class\r│ │ └── ...\r│ ├── images // images that need to be protected\r│ │ ├── user_icon.png\r│ │ └── ...\r│ └── lib\r│ └── javax.servlet-api-3.0.1.jar\r├── index.jsp\r├── readme.txt //instructions for setting up the environment ⚠️ Note Servlet api version 3.0.x is supported by Tomcat 7.0.76. If you are using a different version of Tomcat, you may need to change the version of the servlet api jar file.\nImplementation User Authentication Login For simplicity, the login page is implemented inside index.jsp. A login form is submitted to the LoginServlet.class. when the user clicks the login button.\nSince this was a school project, the username and password are hard-coded in the Controller layer. In a real-world application, the username and password should be stored in a database and accessed by Data Access Object(DAO) layer.\nprivate final String fakeUsername = \u0026#34;admin\u0026#34;; private final String fakePassword = \u0026#34;admin\u0026#34;; String username = request.getParameter(\u0026#34;username\u0026#34;); String password = request.getParameter(\u0026#34;password\u0026#34;); boolean inputMatches = fakeUserName.equals(username) \u0026amp;\u0026amp; fakePassword.equals(password); if (inputMatches) { session.setAttribute(\u0026#34;userId\u0026#34;,username); response.sendRedirect(\u0026#34;aboutme\u0026#34;); return; } Source LoginServlet.java\n⚠️ Note As the user authentication details, such as the username and password, are transmitted through an HTML form, it is recommended to implement the authentication logic in the doPost() method rather than the doGet() method. Otherwise, the user authentication information will be exposed in the URL, causing security issues.\nLogout The logout page is much simpler. It only needs to invalidate the session and redirect the user to the login page. This logic can be implemented inside either the doGet() method or the doPost() method.\nHttpSession session = request.getSession(false); if (session != null) { session.removeAttribute(\u0026#34;userId\u0026#34;); } response.sendRedirect(\u0026#34;index.jsp\u0026#34;); Source Logout.java\nSecured Content Pages For each protected content page, the servlet class needs to check if the user has logged in. If the user has not logged in, the servlet class will redirect the user to the login page.\nCheck if the user has logged in:\n// check if user is logged in HttpSession session = request.getSession(false); if (session == null || session.getAttribute(\u0026#34;userId\u0026#34;) == null) { response.sendRedirect(\u0026#34;index.jsp\u0026#34;); return; } Disable Caching:\nresponse.setHeader(\u0026#34;Cache-Control\u0026#34;, \u0026#34;no-cache, no-store, must-revalidate\u0026#34;); response.setHeader(\u0026#34;Pragma\u0026#34;, \u0026#34;no-cache\u0026#34;); response.setDateHeader(\u0026#34;Expires\u0026#34;, 0); Actually writing the content of the page:\nresponse.setContentType(\u0026#34;text/html\u0026#34;); PrintWriter out = response.getWriter(); out.println(\u0026#34;\u0026lt;html\u0026gt;\u0026#34;); out.println(\u0026#34;\u0026lt;head\u0026gt;\u0026#34;); out.println(\u0026#34;\u0026lt;title\u0026gt;AboutMe\u0026lt;/title\u0026gt;\u0026#34;); out.println(\u0026#34;\u0026lt;link rel=\\\u0026#34;stylesheet\\\u0026#34; href=\\\u0026#34;css/reset.css\\\u0026#34;\u0026gt;\u0026#34;); out.println(\u0026#34;\u0026lt;link rel=\\\u0026#34;stylesheet\\\u0026#34; href=\\\u0026#34;css/useDefaultCursor.css\\\u0026#34;\u0026gt;\u0026#34;); out.println(\u0026#34;\u0026lt;link rel=\\\u0026#34;stylesheet\\\u0026#34; href=\\\u0026#34;css/preventPrint.css\\\u0026#34;\u0026gt;\u0026#34;); out.println(\u0026#34;\u0026lt;link rel=\\\u0026#34;stylesheet\\\u0026#34; href=\\\u0026#34;css/credit.css\\\u0026#34;\u0026gt;\u0026#34;); out.println(\u0026#34;\u0026lt;link rel=\\\u0026#34;stylesheet\\\u0026#34; href=\\\u0026#34;css/profile.css\\\u0026#34;\u0026gt;\u0026#34;); out.println(\u0026#34;\u0026lt;link rel=\\\u0026#34;stylesheet\\\u0026#34; href=\\\u0026#34;css/aboutme.css\\\u0026#34;\u0026gt;\u0026#34;); out.println(\u0026#34;\u0026lt;/head\u0026gt;\u0026#34;); out.println(\u0026#34;\u0026lt;body\u0026gt;\u0026#34;); ... out.println(\u0026#34;\u0026lt;/body\u0026gt;\u0026#34;); out.println(\u0026#34;\u0026lt;script src=\u0026#39;js/disableSelection.js\u0026#39;\u0026gt;\u0026lt;/script\u0026gt;\u0026#34;); out.println(\u0026#34;\u0026lt;script src=\u0026#39;js/disableSavingImg.js\u0026#39;\u0026gt;\u0026lt;/script\u0026gt;\u0026#34;); out.println(\u0026#34;\u0026lt;script src=\u0026#39;js/disableDragging.js\u0026#39;\u0026gt;\u0026lt;/script\u0026gt;\u0026#34;); out.println(\u0026#34;\u0026lt;/html\u0026gt;\u0026#34;); Source AboutMeServlet.java\nImage Protection The images that need to be protected are put into the WEB-INF folder. WEB-INF folder is a special folder which is protected by web application containers like Tomcat. Anything inside will not be accessable directly through a URL such as https://www.example.com/WEB-INF/images/user_icon.png\nTo read the image file, pass the relative path of the image file to the Servlet API:\n// path: \u0026#34;/WEB-INF/images/user_icon.png\u0026#34; InputStream inputStream = context.getResourceAsStream(path); Finally read the Input Stream and convert the image into data URI schemes to completely hide the image URL:\nimageStr = Base64.getEncoder().encodeToString(imageData); Source ImageHelper.java\nThen include the URI schemes in the HTML:\nout.println(\u0026#34;\u0026lt;img src=\u0026#39;data:image/png;base64,\u0026#34; + imageStr + \u0026#34;\u0026#39; /\u0026gt;\u0026#34;); Source AboutMeServlet.java\nPreventing Unwanted User Actions To prevent users from saving images on the web pages:\ndocument.addEventListener( \u0026#34;contextmenu\u0026#34;, function (e) { e.preventDefault(); }, false ); Source disableSavingImg.js\nTo prevent users from selecting text on the web pages:\nif (typeof document.onselectstart != \u0026#34;undefined\u0026#34;) { document.onselectstart = new Function(\u0026#34;return false\u0026#34;); } else { document.onmousedown = function () { return false; }; document.onmouseup = function () { return true; }; } Source disableSelection.js\nTo prevent users from dragging images on the web pages:\ndocument.addEventListener(\u0026#34;dragstart\u0026#34;, function (event) { event.preventDefault(); }); Source disableDragging.js\nTo prevent users from printing the web pages:\n@media print { body * { visibility: hidden; } } Source preventPrint.css\nDeployment Step 0: Prerequisites (Done by the server administrator) Install JavaSE 8 on the server machine. Install Apache Tomcat 7.0.76 on the server machine. Step 1: Download SSH/FTP client For windows users:\nSSH client: Putty FTP client: WinSCP Step 2: Upload the website folder to the server tag every servlet class with @WebServlet(\u0026quot;/path\u0026quot;) annotation. @WebServlet(\u0026#34;/aboutme\u0026#34;)\rpublic class AboutMeServlet extends HttpServlet {\r...\r} path is the URL path to access the servlet. For example, the above servlet can be accessed by the URL: http://localhost:8080/itec4020grp9/aboutme\nalternitively, add the following code to the web.xml file to map the servlet to a URL path. The web.xml file should be created in the WEB-INF folder like this:\n\u0026lt;web-app xmlns=\u0026#34;http://java.sun.com/xml/ns/javaee\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd\u0026#34; version=\u0026#34;3.0\u0026#34;\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;AboutMeServlet\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;AboutMeServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;/servlet\u0026gt; ... \u0026lt;/web-app\u0026gt; To include Servlets to the web.xml file:\n\u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;MyServlet\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;/path/to/myServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;/servlet\u0026gt; To include JSP files to the web.xml file:\n\u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;MyJsp\u0026lt;/servlet-name\u0026gt; \u0026lt;jsp-file\u0026gt;/path/to/myJsp\u0026lt;/jsp-file\u0026gt; \u0026lt;/servlet\u0026gt; Note\nThe path does not need to include the file extension. The path is relative to the WEB-INF/classes folder. make sure all Java Servlet classes are compiled into WEB-INF/classes folder. Step 3: Deploy the website on the Tomcat server To deploy the website on the Tomcat server, simply copy the website folder to the webapps folder of the Tomcat server. Step 4: Making changes to the website Upload the changes to the server. Restart the Tomcat server. Not Practical if you are not the server administrator. Alternatively, slightly changing the web.xml file back and forth will trigger a kind of reload event inside Tomcat. Not Elegant but Practical😗 Test Cases Case 1 A user cannot get into the secured Web information system after logout by clicking on the browser\u0026rsquo;s back button or typing in the URL address directly.\nCase 2 The user has to login using userid and password in order to get into the secured website after logout.\nCase 3 All the URL addresses of the secured Web information system need to be protected.\nCase 4 The image files of secured Web pages shouldn’t be allowed to save on the client’s local machine.\nCase 5 After closing the browser, the user cannot get into the secured Web information system without login again.\nCase 6 Users cannot copy and paste the text information on the secured Web pages.\nCase 7 Some secured pages should not be able to be printed, for example, by using a browser’s print function.\nCase 8 Information on the server side(e.g. Image URL) should be protected.\nFuture Improvements Use a database to store user information instead of hard-coding the user information in the Java Servlet code. Use \u0026lt;canvas\u0026gt; tags on html to display the secured content pages instead of disabling user actions on the web pages. Because disabling user actions may have a negative impact on the overall user experience and the logic is handled on the client-side which is not secure. Conclusion In conclusion, I have successfully implemented a secured web information system. The system is secured by using HTTPS, Tomcat and Java Servlet. The system is protected from unauthorized user accesses and also protected from unwanted user actions such as saving images, selecting text, dragging images, and printing the web pages.\n","permalink":"https://sky-haihai.github.io/Yaotian-Huang/posts/uni/secured-web-information-system-prototype/","summary":"View the full project here: Github Repo\nIntroduction In a recent academic project, I implemented a secured web information system using Java Servlet and created several content pages including AboutMe, Skills, and Contact pages for testing my system.\nThe goal was to implement a web application that could allow users to login, logout and view their profile. The application also had to be secured against unauthorized access such as directly typing the content page URL.","title":"Secured Web Information System Prototype"},{"content":"View the full project here: Github Repo\nIntroduction In a recent academic project, I created an efficient indexer and search engine for a collection of Web documents. My goal was to implement an program that could create an inverted index for the provided Web documents(.GZ files), and search these web documents for 20 topics/queries, outputting the search results in a file.\nInput a bunch of .GZ files, each containing multiple XML web documents. Each xml doc contains multiple articles.\n.GZ file XML file Article 1 Article 2 Article 3 ... Article n Each document looks like this:\n\u0026lt;DOC\u0026gt; \u0026lt;DOCNO\u0026gt;WT01-B01-1\u0026lt;/DOCNO\u0026gt; \u0026lt;DOCOLDNO\u0026gt;IA073-000475-B029-48\u0026lt;/DOCOLDNO\u0026gt; \u0026lt;DOCHDR\u0026gt; \u0026lt;!-- Document Description --\u0026gt; \u0026lt;/DOCHDR\u0026gt; \u0026lt;html\u0026gt; \u0026lt;!-- Web Content --\u0026gt; \u0026lt;/html\u0026gt; \u0026lt;/DOC\u0026gt; Each topic looks like this:\n\u0026lt;top\u0026gt; \u0026lt;num\u0026gt; Number: 401 \u0026lt;title\u0026gt; foreign minorities, Germany \u0026lt;desc\u0026gt; Description: What language and cultural differences impede the integration of foreign minorities in Germany? \u0026lt;narr\u0026gt; Narrative: A relevant document will focus on the causes of the lack of integration in a significant way; that is, the mere mention of immigration difficulties is not relevant. Documents that discuss immigration problems unrelated to Germany are also not relevant. \u0026lt;/top\u0026gt; Output Query results for 20 topics\nChallenges The size of the raw token(word) collection is too large to be loaded into RAM. The documents are in XML format and some documents partially miss nessessary tags like \u0026lt;html\u0026gt;, which is not easy to parse. The documents are in different encodings, which adds difficulty to the pre-processing module. Approach Overview 1. Pre-Processing · Unzip GZ files and read them as XML. · Pre-process XML into document number dictionary { docno: docoldno } and word dictionary {docno: [word1, word2, …..]}. 2. Building the Inverted Index · Build the inverted indexer using the word dictionary. · Group by initial and save each file into an individual JSON file to save RAM usage when applying searching. 3. Searching · Apply the vector space model to calculate the similarity between the query and each document. · Sort the similarity and output the top 1000 results for each query. Pre-Processing Unzipping GZ ... for filename in files: if filename.endswith(\u0026#39;.GZ\u0026#39;) or filename.endswith(\u0026#39;.gz\u0026#39;): gz_file = os.path.join(root, filename) with gzip.open(gz_file, \u0026#39;rt\u0026#39;, encoding=\u0026#39;utf-errors=\u0026#39;ignore\u0026#39;) as file: xml_content = file.read() result.append(xml_content) ... Natural Language Processing Import nltk and download essential data from nltk server:\nimport nltk nltk.download(\u0026#39;stopwords\u0026#39;) nltk.download(\u0026#39;punkt\u0026#39;) nltk.download(\u0026#39;words\u0026#39;) Tokenize all html contents and apply stemming to keep original english word only:\ntokens = word_tokenize(content_str) tokens = [word.lower() for word in tokens if word.isalpha()] filtered_tokens = [word for word in tokens if word not in stop_words] stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens] only_words = [word for word in stemmed_tokens if word in english_words] Note\nStick with one encoding format, in this case, UTF-8 to avoid decoding errors when web documents contain special characters like Hanzi(Chinese letter) and Hirakana(Japanese word).\nBuilding the Inverted Index At this point, all the web documents have been extracted, tokenized, stemmed into a dictionary: {docno: [word1, word2,...]}.\nNow to build the index, simply count the frequency of each word\nfor docno, words in word_dict.items(): word_counts = Counter(words) for word, count in word_counts.items(): inverted_index[word][docno] += count Searching/Querying Pre-Processing Tokenize the query and apply stemming:\ntopic_tokens = preprocess.topics_to_tokens(topic_file) See preprocess.py\nVector Space Model Treat the query and each documents as a vector. Calculate the similarity between the query vector and each document vector sim = np.dot(query_vector, doc_vector) / (np.linalg.norm(query_vector) * np.linalg.norm(doc_vector)) See calculate_similarity.py\nOptimization Calculating the TF-IDF value instead of dot product to mark the importance of each token (word) during the preprocess stage. Multithreading during the preprocessing stage to speed up the process of reading HTML content and during the index building stage. Using the vector space function for weighting. Utilizing the dot product for calculating similarity in the vector space model. Analysis of Results A full run which involves over 48,000 XML documents(6,000,000 lines) takes approximately 2 hours, which was a significant improvement over the initial 3-hour runtime before implementing multithreading in the preprocessing stage and indexing stage. Each query takes only 250ms to complete in average. Conclusion This project taught me valuable lessons about optimizing search engine algorithms and the importance of efficient indexing for web document retrieval. By using the appropriate data structures, algorithms, and parallel processing techniques, I was able to build an efficient and effective search engine.\n","permalink":"https://sky-haihai.github.io/Yaotian-Huang/posts/uni/information-retrieval-web-document-indexer-and-search-engine-prototype/","summary":"View the full project here: Github Repo\nIntroduction In a recent academic project, I created an efficient indexer and search engine for a collection of Web documents. My goal was to implement an program that could create an inverted index for the provided Web documents(.GZ files), and search these web documents for 20 topics/queries, outputting the search results in a file.\nInput a bunch of .GZ files, each containing multiple XML web documents.","title":"Information Retrieval: Web Document Indexer and Search Engine Prototype"},{"content":"What is XiheFramework XiheFramework is a game framework for agile development, wrote on top of Unity engine.\nWho Should Use Scale Ideally at least two members:\nProgrammer for creating custom modules(game features) Technical designer for node editing Or use it as an individual developer (hair loss rate 200%)\nSkills Unity Editor Node-based Editor C# (Custom Modules) Warning ⚠️ Consider not to use this framework if you are work individually and have ZERO programming skill as you probably will have a lot of pain if you just use the node editor for all game logic. However, this is just a warning, feel free to ignore it.\nThis framework is maintained, updated and probably used only by me so\u0026hellip; free feel to contribute and prepare for major API changes.\nWhere to Download Github Repo\nDocumentation\nWhy Use It Contains out-of-box essential modules for any game. (e.g. Event, FSM, etc..) Uses name-based indexing instead of id-based to save you from tedious work of filling out a bunch of excel sheets. Intergrates FlowCanvas(Not Included) as a Service layer to connect designers to the engine. How to Use (Core Modules) Audio Wrapper of FMOD for Unity. Provides useful functions to play sound with 3D parameters.\nBlackboard Runtime Variable Pool.\nEvent Runtime Event Pool.\nFSM Runtime FSM Pool.\nInput Encapsulation of Unity Legacy Iput System. Provide useful features like Keyboard remapping and useful functions for mouse movement.\nLocalization Get text and assets(textures, models) that match the current Language setting.\nSerialization Serialize runtime data into binary data to save the game progress.\nUI Manage all UI Behaviour(Canvas) states.\nRead detailed documentation with use cases\nDependencies FlowCanvas (Mandatory)\nFMod (Mandatory)\n","permalink":"https://sky-haihai.github.io/Yaotian-Huang/posts/gamedev/introducing-xiheframework/","summary":"What is XiheFramework XiheFramework is a game framework for agile development, wrote on top of Unity engine.\nWho Should Use Scale Ideally at least two members:\nProgrammer for creating custom modules(game features) Technical designer for node editing Or use it as an individual developer (hair loss rate 200%)\nSkills Unity Editor Node-based Editor C# (Custom Modules) Warning ⚠️ Consider not to use this framework if you are work individually and have ZERO programming skill as you probably will have a lot of pain if you just use the node editor for all game logic.","title":"Introducing Xiheframework"}]